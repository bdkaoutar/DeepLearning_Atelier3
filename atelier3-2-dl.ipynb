{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets accelerate\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:57:00.099530Z","iopub.execute_input":"2025-12-18T13:57:00.099838Z","iopub.status.idle":"2025-12-18T13:57:04.525363Z","shell.execute_reply.started":"2025-12-18T13:57:00.099812Z","shell.execute_reply":"2025-12-18T13:57:04.524412Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nprint(\"CUDA available:\", torch.cuda.is_available())\nprint(\"GPU:\", torch.cuda.get_device_name(0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:57:07.408995Z","iopub.execute_input":"2025-12-18T13:57:07.409713Z","iopub.status.idle":"2025-12-18T13:57:10.744175Z","shell.execute_reply.started":"2025-12-18T13:57:07.409675Z","shell.execute_reply":"2025-12-18T13:57:10.743513Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nGPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# **Load WikiText-103 Dataset**","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\")\nprint(dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:57:14.015404Z","iopub.execute_input":"2025-12-18T13:57:14.016017Z","iopub.status.idle":"2025-12-18T13:57:28.405927Z","shell.execute_reply.started":"2025-12-18T13:57:14.015990Z","shell.execute_reply":"2025-12-18T13:57:28.405379Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b8a118c0aa04c2ba3f06bee53582c0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"wikitext-103-raw-v1/test-00000-of-00001.(…):   0%|          | 0.00/733k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77fe408f967f49eeb5d17e8357bd64a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"wikitext-103-raw-v1/train-00000-of-00002(…):   0%|          | 0.00/157M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5551d92cfca46ef94b47a39c6411ec7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"wikitext-103-raw-v1/train-00001-of-00002(…):   0%|          | 0.00/157M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24c3bf82c7924ec2a0f0d58ad0a6ef99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"wikitext-103-raw-v1/validation-00000-of-(…):   0%|          | 0.00/657k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85aae265e722456993637b1883f22735"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a185dbec8bc49da91c9bad25366efcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9db256ef4ea547ba9a628018081851c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a99f4b3672a4be398d895a813909890"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    test: Dataset({\n        features: ['text'],\n        num_rows: 4358\n    })\n    train: Dataset({\n        features: ['text'],\n        num_rows: 1801350\n    })\n    validation: Dataset({\n        features: ['text'],\n        num_rows: 3760\n    })\n})\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# **Dataset Builder (20k+ Clean Paragraphs)**","metadata":{}},{"cell_type":"code","source":"def build_paragraph_dataset(\n    texts,\n    min_words=30,\n    max_samples=20000\n):\n    paragraphs = []\n\n    for text in texts:\n        text = text.strip()\n\n        if len(text.split()) >= min_words:\n            sample = (\n                \"<|endoftext|>\\n\"\n                f\"{text}\\n\"\n                \"<|endoftext|>\"\n            )\n            paragraphs.append(sample)\n\n        if len(paragraphs) >= max_samples:\n            break\n\n    return paragraphs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:57:42.093292Z","iopub.execute_input":"2025-12-18T13:57:42.094311Z","iopub.status.idle":"2025-12-18T13:57:42.098955Z","shell.execute_reply.started":"2025-12-18T13:57:42.094270Z","shell.execute_reply":"2025-12-18T13:57:42.098254Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## **Build the Dataset**","metadata":{}},{"cell_type":"code","source":"raw_texts = dataset[\"train\"][\"text\"]\n\nparagraphs = build_paragraph_dataset(\n    raw_texts,\n    min_words=30,\n    max_samples=20000   # >= 20k as required\n)\n\nprint(\"Total paragraphs:\", len(paragraphs))\nprint(\"\\nSample paragraph:\\n\", paragraphs[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:57:55.072755Z","iopub.execute_input":"2025-12-18T13:57:55.073484Z","iopub.status.idle":"2025-12-18T13:57:55.954857Z","shell.execute_reply.started":"2025-12-18T13:57:55.073454Z","shell.execute_reply":"2025-12-18T13:57:55.954233Z"}},"outputs":[{"name":"stdout","text":"Total paragraphs: 20000\n\nSample paragraph:\n <|endoftext|>\nSenjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" .\n<|endoftext|>\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## **Save to Text File**","metadata":{}},{"cell_type":"code","source":"with open(\"wikitext_paragraphs.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.write(\"\\n\".join(paragraphs))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:58:12.954015Z","iopub.execute_input":"2025-12-18T13:58:12.954636Z","iopub.status.idle":"2025-12-18T13:58:13.009500Z","shell.execute_reply.started":"2025-12-18T13:58:12.954607Z","shell.execute_reply":"2025-12-18T13:58:13.008884Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# **Load GPT-2 Model & Tokenizer**","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel\n\nmodel_name = \"gpt2\"  # small GPT-2 (fits P100 well)\n\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\n\ntokenizer.pad_token = tokenizer.eos_token\nmodel.resize_token_embeddings(len(tokenizer))\n\nmodel.to(\"cuda\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:58:26.133008Z","iopub.execute_input":"2025-12-18T13:58:26.133578Z","iopub.status.idle":"2025-12-18T13:58:52.547168Z","shell.execute_reply.started":"2025-12-18T13:58:26.133548Z","shell.execute_reply":"2025-12-18T13:58:52.546510Z"}},"outputs":[{"name":"stderr","text":"2025-12-18 13:58:34.793019: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766066314.967561      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766066315.021950      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766066315.426629      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766066315.426669      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766066315.426672      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766066315.426674      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3788c3ece5d43168b477adf18a65864"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b74636e6d6c349c09e9fd00e75be0ee0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48be62f8ab6e45b78b4b5f677bc4cf7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a92e1234c5b487a980d96f3abb7a89f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8329fa74acdd433495cc16d4728965ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca58a58367f24e2685bfeca6be8e3af0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e5785d83a884f69a9d43c68c04c27ff"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D(nf=2304, nx=768)\n          (c_proj): Conv1D(nf=768, nx=768)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=3072, nx=768)\n          (c_proj): Conv1D(nf=768, nx=3072)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# **Tokenization & Block Processing**","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ntext_dataset = load_dataset(\n    \"text\",\n    data_files=\"wikitext_paragraphs.txt\"\n)[\"train\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:58:53.076177Z","iopub.execute_input":"2025-12-18T13:58:53.076448Z","iopub.status.idle":"2025-12-18T13:58:53.154025Z","shell.execute_reply.started":"2025-12-18T13:58:53.076421Z","shell.execute_reply":"2025-12-18T13:58:53.153526Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"block_size = 128\n\ndef tokenize_function(examples):\n    return tokenizer(\n        examples[\"text\"],\n        truncation=True,\n        max_length=block_size\n    )\n\ntokenized_dataset = text_dataset.map(\n    tokenize_function,\n    batched=True,\n    remove_columns=[\"text\"]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:59:06.203752Z","iopub.execute_input":"2025-12-18T13:59:06.204333Z","iopub.status.idle":"2025-12-18T13:59:29.248729Z","shell.execute_reply.started":"2025-12-18T13:59:06.204303Z","shell.execute_reply":"2025-12-18T13:59:29.248073Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/60000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8945f869c34b45c59f4bd3997e84119e"}},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## **Group Tokens into Blocks**","metadata":{}},{"cell_type":"code","source":"def group_texts(examples):\n    concatenated = {k: sum(examples[k], []) for k in examples.keys()}\n    total_length = len(concatenated[\"input_ids\"])\n    total_length = (total_length // block_size) * block_size\n\n    result = {\n        k: [\n            t[i : i + block_size]\n            for i in range(0, total_length, block_size)\n        ]\n        for k, t in concatenated.items()\n    }\n    result[\"labels\"] = result[\"input_ids\"].copy()\n    return result\n\nlm_dataset = tokenized_dataset.map(group_texts, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T14:00:17.215267Z","iopub.execute_input":"2025-12-18T14:00:17.216093Z","iopub.status.idle":"2025-12-18T14:00:26.534677Z","shell.execute_reply.started":"2025-12-18T14:00:17.216062Z","shell.execute_reply":"2025-12-18T14:00:26.534078Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/60000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e63cdc19e8d43c294244f7d63f8a53f"}},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# **Fine-Tuning Setup**","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nfrom transformers import DataCollatorForLanguageModeling\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T14:01:17.209841Z","iopub.execute_input":"2025-12-18T14:01:17.210525Z","iopub.status.idle":"2025-12-18T14:01:18.895672Z","shell.execute_reply.started":"2025-12-18T14:01:17.210489Z","shell.execute_reply":"2025-12-18T14:01:18.895091Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"data_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T14:01:50.643236Z","iopub.execute_input":"2025-12-18T14:01:50.643747Z","iopub.status.idle":"2025-12-18T14:01:50.647296Z","shell.execute_reply.started":"2025-12-18T14:01:50.643721Z","shell.execute_reply":"2025-12-18T14:01:50.646583Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"/kaggle/working/gpt2-wikitext-finetuned\",\n    overwrite_output_dir=True,\n    num_train_epochs=3,          # WikiText is clean; 3 epochs is enough\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=4,  # effective batch = 16\n    learning_rate=2e-5,\n    warmup_steps=100,\n    fp16=True,\n    logging_steps=100,\n    save_steps=1000,\n    save_total_limit=2,\n    report_to=\"none\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T14:01:53.430995Z","iopub.execute_input":"2025-12-18T14:01:53.431592Z","iopub.status.idle":"2025-12-18T14:01:53.460685Z","shell.execute_reply.started":"2025-12-18T14:01:53.431561Z","shell.execute_reply":"2025-12-18T14:01:53.460142Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# **Train the Model**","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=lm_dataset,\n    data_collator=data_collator\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T14:01:55.689064Z","iopub.execute_input":"2025-12-18T14:01:55.689871Z","iopub.status.idle":"2025-12-18T14:21:07.778748Z","shell.execute_reply.started":"2025-12-18T14:01:55.689839Z","shell.execute_reply":"2025-12-18T14:21:07.778153Z"}},"outputs":[{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3267' max='3267' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3267/3267 19:10, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>4.119900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>3.737700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>3.700200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.644900</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>3.611100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.601800</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>3.562200</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>3.580900</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>3.554500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.571100</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>3.539200</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>3.484000</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>3.484300</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>3.476700</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>3.477500</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>3.471400</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>3.456500</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>3.466100</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>3.449900</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>3.482100</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>3.443200</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>3.452500</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>3.414500</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>3.419400</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>3.422100</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>3.401700</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>3.396800</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>3.409500</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>3.430000</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>3.409300</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>3.413100</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>3.410000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3267, training_loss=3.5131947470981117, metrics={'train_runtime': 1151.6629, 'train_samples_per_second': 45.365, 'train_steps_per_second': 2.837, 'total_flos': 3412800552960000.0, 'train_loss': 3.5131947470981117, 'epoch': 3.0})"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"## **Save the Fine-Tuned Model**","metadata":{}},{"cell_type":"code","source":"trainer.save_model(\"/kaggle/working/gpt2-wikitext-finetuned\")\ntokenizer.save_pretrained(\"/kaggle/working/gpt2-wikitext-finetuned\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T14:37:02.676233Z","iopub.execute_input":"2025-12-18T14:37:02.676823Z","iopub.status.idle":"2025-12-18T14:37:03.762864Z","shell.execute_reply.started":"2025-12-18T14:37:02.676793Z","shell.execute_reply":"2025-12-18T14:37:03.762297Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/gpt2-wikitext-finetuned/tokenizer_config.json',\n '/kaggle/working/gpt2-wikitext-finetuned/special_tokens_map.json',\n '/kaggle/working/gpt2-wikitext-finetuned/vocab.json',\n '/kaggle/working/gpt2-wikitext-finetuned/merges.txt',\n '/kaggle/working/gpt2-wikitext-finetuned/added_tokens.json')"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# **Text Generation**","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\ngenerator = pipeline(\n    \"text-generation\",\n    model=\"/kaggle/working/gpt2-wikitext-finetuned\",\n    tokenizer=tokenizer,\n    device=0\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T14:37:05.482672Z","iopub.execute_input":"2025-12-18T14:37:05.482934Z","iopub.status.idle":"2025-12-18T14:37:05.994783Z","shell.execute_reply.started":"2025-12-18T14:37:05.482912Z","shell.execute_reply":"2025-12-18T14:37:05.994210Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## **Generate a New Paragraph from a Sentence**","metadata":{}},{"cell_type":"code","source":"prompt = \"Artificial intelligence is transforming modern society by\"\n\noutputs = generator(\n    prompt,\n    max_new_tokens=150,\n    num_return_sequences=3,\n    temperature=0.7,\n    top_p=0.9,\n    do_sample=True,\n    repetition_penalty=1.2,\n    eos_token_id=tokenizer.eos_token_id,\n    pad_token_id=tokenizer.eos_token_id\n)\n\nfor i, out in enumerate(outputs):\n    print(f\"\\nGenerated {i+1}:\\n{out['generated_text']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T14:37:07.992467Z","iopub.execute_input":"2025-12-18T14:37:07.993218Z","iopub.status.idle":"2025-12-18T14:37:09.889912Z","shell.execute_reply.started":"2025-12-18T14:37:07.993187Z","shell.execute_reply":"2025-12-18T14:37:09.889311Z"}},"outputs":[{"name":"stdout","text":"\nGenerated 1:\nArtificial intelligence is transforming modern society by increasing the size of our digital networks, enabling us to organize and communicate with each other. AI will replace human knowledge in a way that makes it more accessible for everyone else through smart devices such as computers or robotics ; this can be accomplished via an increase on privacy @-@ protections which allow people who have not been affected directly from being able access information about their surroundings without fear thereof ( i.e., no threat ) [ 1 ] –[ 2 ]. In addition, artificial intelligences may enhance communication between humans using technologies like Artificial Intelligence Technologies \" : Smartphones are now connected wirelessly — they do so because these new methods offer greater reliability than existing communications systems were designed at first but still provide lower cost per unit time compared wiener technology would otherwise\n\nGenerated 2:\nArtificial intelligence is transforming modern society by enabling people to live more comfortably and better lives. It has been shown that the number of jobs available for AI scientists are growing faster than other industries, including healthcare : in 2008 an estimated 6 @,@ 000 companies were listed on The New York Stock Exchange as part \" Artificial Intelligence Companies \". There have also been several reports about how machines will improve everyday life ( e.g., a study conducted at MIT showed robots can be programmed into homes ; one report found their use was increasing rapidly ) – such effects would appear within decades or even centuries without human intervention if not already happening before humans began exploring new technologies! This rapid development may therefore give rise to widespread applications where intelligent computers could help create products far beyond traditional methods like computer graphics processing algorithms used today\n\nGenerated 3:\nArtificial intelligence is transforming modern society by making it possible for scientists to do things that humans have never done before. In this regard, AI has been increasingly used as a tool of propaganda and social engineering in the US media industry ; many companies are using these technologies against their customers so they can profit from its use without fear or favoritism ( such tactics may also be employed at home ) : Google's self @-@ funded Deep Blue Project was launched with funding through an initial round led by founder Larry Page which resulted into one company being awarded $ 5 million per year within six months after launching two years later on June 1 2013 – although some employees were fired due \" not only insufficient funds but lack interest \". A number other high profile projects include Artificial Intelligence Research Initiative The International Group For Advanced\n","output_type":"stream"}],"execution_count":18}]}